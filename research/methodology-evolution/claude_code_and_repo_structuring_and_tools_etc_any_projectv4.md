# Claude Code & Repository Structure Decisions (Any Project)

## Project Context Template
[Describe your project's purpose, stakeholders, and constraints here]

## Core Architectural Decisions

### 1. Documentation Structure
**Decision**: Three-tier documentation approach
- **`docs/behavior/`** - WHAT the system should do (requirements, goals, uncertainties)
- **`docs/architecture/`** - HOW to build the system (technical design, components)
- **`docs/development_roadmap/`** - CURRENT STATUS and path forward (phases, progress tracking)

**Rationale**: Separates concerns clearly - behavior defines requirements, architecture defines implementation approach, roadmap tracks execution progress.

### 2. Phase Management Strategy
**Decision**: Dual-file phase tracking
- **`phases.md`** - High-level overview with status checkboxes and references
- **`phase_X_name.md`** - Detailed implementation plans for each phase

**Key Rules**:
- **Status lives ONLY in `phases.md`** - single source of truth for completion tracking
- **Phase files are status-neutral** - contain implementation details, not current state
- **CLAUDE.md references both** - gets status from phases.md, gets details from phase files

**Rationale**: Allows quick status checks while maintaining detailed implementation guidance. Prevents contradictory status claims across multiple files.

### 3. Directory Structure & Organization
```
/
‚îú‚îÄ‚îÄ CLAUDE.md                    # Current implementation plan (auto-updated)
‚îú‚îÄ‚îÄ project_architecture.md     # This file - architectural decisions
‚îú‚îÄ‚îÄ src/                         # Main codebase
‚îÇ   ‚îú‚îÄ‚îÄ [component_1]/          # Primary component/module
‚îÇ   ‚îú‚îÄ‚îÄ [component_2]/          # Secondary component/module
‚îÇ   ‚îî‚îÄ‚îÄ [component_3]/          # Additional components as needed
‚îú‚îÄ‚îÄ docs/                       # Permanent documentation
‚îÇ   ‚îú‚îÄ‚îÄ behavior/               # System requirements and goals
‚îÇ   ‚îú‚îÄ‚îÄ architecture/           # Technical design documents
‚îÇ   ‚îî‚îÄ‚îÄ development_roadmap/    # Phase planning and status tracking
‚îú‚îÄ‚îÄ investigations/             # Technical research and LLM debugging
‚îÇ   ‚îú‚îÄ‚îÄ [area_1]/              # Investigation area (e.g., authentication)
‚îÇ   ‚îú‚îÄ‚îÄ [area_2]/              # Investigation area (e.g., performance)
‚îÇ   ‚îú‚îÄ‚îÄ [area_3]/              # Investigation area (e.g., integration)
‚îÇ   ‚îî‚îÄ‚îÄ errors/                # Error pattern analysis and debugging
‚îú‚îÄ‚îÄ research/                  # Domain knowledge and strategy research
‚îÇ   ‚îú‚îÄ‚îÄ [domain_1]/            # Domain area (e.g., market analysis)
‚îÇ   ‚îú‚îÄ‚îÄ [domain_2]/            # Domain area (e.g., user research)
‚îÇ   ‚îî‚îÄ‚îÄ [domain_3]/            # Domain area (e.g., competitors)
‚îú‚îÄ‚îÄ tests/                     # All test files
‚îÇ   ‚îú‚îÄ‚îÄ unit/                  # Component tests
‚îÇ   ‚îú‚îÄ‚îÄ integration/           # API and system integration tests
‚îÇ   ‚îî‚îÄ‚îÄ e2e/                   # End-to-end workflow tests
‚îú‚îÄ‚îÄ data/                      # Data pipeline storage (if applicable)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                   # Unprocessed data from external sources
‚îÇ   ‚îî‚îÄ‚îÄ processed/             # Cleaned and analyzed data
‚îú‚îÄ‚îÄ config/                    # Configuration files and settings
‚îú‚îÄ‚îÄ tools/                     # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ workflow/             # Autonomous workflow tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workflow_orchestrator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evidence_validator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ discovery_classifier.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state_reconciliation.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ uncertainty_resolver.py
‚îÇ   ‚îú‚îÄ‚îÄ validate_references.py
‚îÇ   ‚îú‚îÄ‚îÄ load_context.py
‚îÇ   ‚îî‚îÄ‚îÄ inject_error.py
‚îú‚îÄ‚îÄ logs/                      # Structured logging system (see Error Management)
‚îÇ   ‚îú‚îÄ‚îÄ errors/                # Error tracking and resolution
‚îÇ   ‚îú‚îÄ‚îÄ debug/                 # Component-specific debug logs
‚îÇ   ‚îî‚îÄ‚îÄ investigation/         # Research session logs
‚îú‚îÄ‚îÄ output/                    # Generated deliverables
‚îÇ   ‚îî‚îÄ‚îÄ [output_type]/         # Project-specific output directories
‚îú‚îÄ‚îÄ .gitignore                # Exclude archive and logs from version control
‚îî‚îÄ‚îÄ .claude/                   # Claude Code configuration
    ‚îú‚îÄ‚îÄ commands/              # Custom slash commands
    ‚îÇ   ‚îî‚îÄ‚îÄ [command_group]/   # Grouped custom commands
    ‚îú‚îÄ‚îÄ evaluations/           # Fresh instance evaluations for anti-cheating
    ‚îÇ   ‚îú‚îÄ‚îÄ eval_[timestamp]/  # Individual evaluation sessions
    ‚îÇ   ‚îî‚îÄ‚îÄ evaluation_history.log  # Log of all evaluations
    ‚îî‚îÄ‚îÄ .lock/                 # Hook synchronization locks
        ‚îî‚îÄ‚îÄ stop.lock          # Prevents concurrent Stop hook races
```

### 4. Directory Purpose & Generalizability
**Decision**: Distinguish between technical investigation and domain research

**Investigations vs Research**:
- **`investigations/`**: Technical research for implementation (LLM debugging, tool building, API analysis)
  - Used heavily by Claude Code for documenting technical discoveries
  - Focus: "How do I build this?" and "Why isn't this working?"
  - Examples: API endpoint discovery, authentication analysis, error debugging
  
- **`research/`**: Domain knowledge and business strategy research  
  - Focus: "What should I build?" and "Why does this matter?"
  - Examples: User needs analysis, competitive research, business requirements

**Data vs Output**:
- **`data/`**: Input data pipeline (raw ‚Üí processed)
  - `raw/`: Unprocessed data from external sources
  - `processed/`: Cleaned, enriched, analysis-ready data
  
- **`output/`**: Generated deliverables for human consumption
  - Project-specific subdirectories (reports/, exports/, visualizations/)

**Generalizability Assessment**:
- **Universal (works for any project)**: docs/, src/, tests/, tools/, config/, logs/, .claude/
- **Research-heavy projects**: investigations/, research/ 
- **Data projects**: data/raw/, data/processed/
- **Project-specific**: Subdirectories within research/ and output/

**Template for new projects**: Start with universal directories, add investigations/ and research/ for research-heavy work, add data/ for data processing projects.

### 5. Archival System with Provenance
**Decision**: Mirror codebase structure in external archive with dated files and decision records

**Archive Location**: `/home/brian/projects/archive/[project_name]/`
- **External storage**: Keeps archives outside repository to prevent repo bloat
- **Project organization**: Multiple projects can share the external archive space
- **Version control**: Archive is outside git, won't be committed

**Archival Structure**:
- **Mirror organization**: Archive maintains same directory structure as main codebase
- **Dated file naming**: Archived files prefixed with YYYYMMDD_ (e.g., `20250920_old_module.py`)
- **Decision records**: Each archive directory contains `ARCHIVAL_REASON.md` documenting rationale

**When to Archive**:
- File replaced by newer approach with different architecture
- Experimental code that didn't work out  
- Outdated documentation or deprecated configurations
- Code no longer needed for current implementation

**Archival Process**:
1. Create external archive directory: `/home/brian/projects/archive/[project_name]/`
2. Move file to corresponding archive directory with date prefix
3. Create/update ARCHIVAL_REASON.md with context and rationale
4. Update cross-references to point to replacement files
5. Document decision for future reference and learning

**Benefits**:
- **Preserves context** for why changes were made
- **Maintains project history** without cluttering active codebase
- **Enables learning** from previous approaches and decisions
- **Supports rollback** if new approaches prove problematic

## Core Infrastructure Tools

### 6. Cross-Reference Validation System
**Built Tool**: `tools/validate_references.py`
- **Purpose**: Validates all cross-references across Python files, Markdown files, and .ref companion files
- **Features**: Regex-based extraction, broken link detection, structured error reporting
- **Integration**: Git pre-commit hooks block commits with broken references
- **Testing**: Comprehensive unit tests covering all validation scenarios

### 7. Context Loading System  
**Built Tool**: `tools/load_context.py`
- **Purpose**: Loads complete context for any target file before modification
- **Features**: Extracts cross-references, analyzes dependencies, loads full text of related files
- **Usage**: MANDATORY before modifying any file to understand impact
- **Output**: Comprehensive context including behavior docs, architecture docs, phase plans, dependencies

### 8. Error Management System
**Built Tool**: `tools/inject_error.py`
- **Purpose**: Automatically injects errors into CLAUDE.md Active Errors section
- **Features**: Structured error logging, automatic CLAUDE.md updates, resolution tracking
- **Integration**: Fail-fast error handling with detailed log files and resolution instructions
- **Error Types**: Broken references, file moves, import errors, validation failures

### 9. Git Workflow Integration
**Git Hooks Implementation**:
- **Pre-commit hook**: Validates all cross-references before allowing commits
- **Post-commit hook**: Detects file moves and automatically creates reference update tasks
- **Error injection**: Broken references automatically appear in CLAUDE.md for immediate attention

**Benefits**:
- **Prevents broken documentation** from entering the repository
- **Automatic maintenance** of cross-reference integrity
- **Immediate visibility** of issues requiring attention

## Claude Code Workflow Integration

### 10. Error Management Workflow
**Decision**: Fail-fast, fail-loud with automatic CLAUDE.md injection

**Error Flow**:
1. **Error occurs** in any function
2. **Detailed log created** in `logs/errors/active/error_YYYYMMDD_HHMMSS.log`
3. **Concise entry injected** into CLAUDE.md `üö® ACTIVE ERRORS` section
4. **Summary index updated** in `logs/errors/active/summary.json`
5. **Claude investigates** using structured log format
6. **Error removed** from CLAUDE.md when resolved, moved to resolved logs

**Log Structure**:
- **Individual error logs** with full context, reproduction steps, investigation notes
- **Summary index (JSON)** for quick error overview without reading full logs
- **Hierarchical organization** (active/resolved/daily) for efficient navigation
- **Standardized format** with clear sections for context, traceback, debugging info

### 11. Evidence-Based Development
**Decision**: All claims require documented proof in `investigations/`

**Evidence Structure**:
- **Phase-based organization**: `investigations/[area]/phase_X/findings.md`
- **Test results**: `investigations/[area]/phase_X/test_results.log`
- **Implementation proof**: `investigations/[area]/phase_X/implementation_proof.md`
- **State reconciliation**: `investigations/[area]/phase_X/state_reconciliation.log`
- **Evidence manifest**: `investigations/[area]/phase_X/evidence.json`
- **Symlink to current**: `investigations/[area]/current_phase ‚Üí phase_X/`
- **Archive on completion**: `/home/brian/projects/archive/[project]/investigations/[area]/YYYYMMDD_phase_X/`
- **Raw execution logs** and outputs preserved for all validation claims

**Evidence JSON Schema** (`evidence.json`):
```json
{
  "phase": "phase_X",
  "area": "scraping",
  "timestamp": "2025-01-20T14:03:00Z",
  "artifacts": {
    "findings": "findings.md",
    "test_results": "test_results.log",
    "implementation_proof": "implementation_proof.md",
    "state_reconciliation": "state_reconciliation.log",
    "coverage_report": "coverage/summary.json"
  },
  "metrics": {
    "tests_passed": true,
    "test_count": 42,
    "coverage_percentage": 85,
    "confidence": "high",
    "automation_health": "good"
  },
  "validation": {
    "cross_references_valid": true,
    "evidence_complete": true,
    "quality_gates_passed": true,
    "reality_check_passed": true
  }
}
```

**Cross-Reference**: See evidence flow in `hook_mermaid_diagram_full4_w_tdd.txt` for visual representation of evidence capture and archival process.

**Integration with Phases**:
- **No success declarations** without evidence files
- **Phase completion** requires end-to-end validation with documented proof
- **Evidence references** in phases.md for all completed tasks

### 12. Custom Commands Strategy
**Decision**: Phase-agnostic commands that work throughout project lifecycle

**Key Command**: `/update_plans_within_phase`
- **Syncs documentation** between CLAUDE.md, phases.md, and phase files
- **Enforces status centralization** (only phases.md tracks completion)
- **Maintains self-contained CLAUDE.md** for new Claude sessions
- **Integrates error tracking** and evidence requirements

**Cross-Reference**: See workflow diagram at `hook_mermaid_diagram_full4_w_tdd.txt` for visual representation of command flow and hook integration.

**Command Philosophy**:
- **Works at all phases** - not specific to any particular phase
- **Evidence-based updates** - requires proof before marking tasks complete
- **New LLM ready** - updated CLAUDE.md contains everything needed for next steps

### 13. Investigation Workflow
**Decision**: Structured research approach using Claude Code subagents

**Investigation Pattern**:
1. **Parallel research** using multiple subagents for complex topics
2. **Structured documentation** in investigations/ with standardized format
3. **Evidence collection** with raw outputs and analysis
4. **Integration into phases** - findings inform detailed implementation plans

**Documentation Requirements**:
- **Exact steps taken** for reproducibility
- **Complete outputs** for verification
- **Analysis of results** and implications for project goals
- **References to related investigations** and patterns

## Implementation Principles

### 14. Status Management Rules
**CRITICAL RULE**: Status information lives ONLY in `phases.md`
- **Phase files**: Implementation details, technical patterns, code examples (status-neutral)
- **CLAUDE.md**: Current tasks with status from phases.md + details from phase files
- **Evidence files**: Proof of completion, not status claims
- **No contradictory status** across multiple files

**Important Distinction - Status vs State**:
- **Status** (phases.md only): Phase/task completion checkboxes, what is "done" vs "pending"
- **State** (CLAUDE.md workflow_state): Ephemeral agent state like current_command, loop_iterations, last_evidence
- Rule: CLAUDE.md may contain **ephemeral agent state** (loop counters, current command) but **never** phase completion status

### 15. File Organization Discipline
**Strict Rules**:
- **NO temp files in root** - use logs/temp/ or /tmp/
- **Clean up investigations** within 48 hours - move to appropriate directories
- **Archive completed work** to prevent confusion with current efforts
- **Document file placement** in CLAUDE.md for all new file types

### 16. Claude Code Optimization
**Leverage Claude Code Features**:
- **Subagents for complex research** 
- **Multi-Claude workflows** for parallel development streams
- **Custom slash commands** for repeated workflows
- **"Think harder" mode** for complex architectural decisions
- **Testing workflows** with iterative improvement cycles

**Session Management**:
- **Self-contained CLAUDE.md** - new sessions need no external context
- **Clear next steps** always documented
- **Error visibility** immediate for any new Claude session
- **Evidence references** for understanding previous work

### 17. Automated Workflow System
**Decision**: Autonomous execution via Claude Code hooks and command orchestration

**Core Components**:
- **`workflow_orchestrator.py`** - Reads CLAUDE.md state, determines next command via Stop hook
- **`evidence_validator.py`** - Validates evidence meets completion criteria via PostToolUse hook
- **`discovery_classifier.py`** - Categorizes findings as minor/major/strategic via PostToolUse hook
- **`state_reconciliation.py`** - Compares claimed vs actual state, detects automation problems
- **`uncertainty_resolver.py`** - Orchestrates categorization and resolution logic for `/categorize_uncertainties` command

**State Management**:
- CLAUDE.md contains workflow state in structured JSON block
- Loop iteration counters for breaker logic (max 7 iterations)
- Stop hook execution counter for infinite loop prevention (max 3)
- Current command tracking for recovery from session restarts
- Evidence references for validation
- Automation health monitoring

**Command Flow Pattern**:
```
/explore ‚Üí /write_tests ‚Üí /implement ‚Üí /run_tests ‚Üí /doublecheck ‚Üí /reality_check ‚Üí (loop if issues)
```

**Complete Command Set** (see `hook_mermaid_diagram_full4_w_tdd.txt` for visual flow):
- `/load_phase_plans` - Entry point: Read phases.md ‚Üí Update CLAUDE.md state
- `/explore` - Read files, identify unknowns
- `/write_tests` - TDD: Define success criteria first  
- `/implement` - Code to pass tests
- `/run_tests` - Execute test suite
- `/doublecheck` - Verify implementation vs requirements
- `/reality_check` - LLM compares claimed vs actual state, detects automation problems
- `/categorize_uncertainties` - Strategic vs Pre-implementation vs Implementation
- `/review_architecture_behavior` - Check docs for guidance on strategic uncertainties
- `/investigate_pre_impl` - Research unknowns
- `/update_plans_within_phase` - Integrate findings ‚Üí CLAUDE.md
- `/escalate_to_deferred` - Archive unresolved to investigations/deferred/
- `/close_phase` - Archive evidence, update phases.md
- `/validate_phase_completion` - Verify evidence, test coverage, quality
- `/review_docs_between_phases` - Check architecture/behavior alignment
- `/load_next_phase` - Update CLAUDE.md with next phase

**CLAUDE.md Workflow State Block**:
```json
{
  "workflow_state": {
    "current_command": "/implement",
    "current_phase": "phase_2",
    "loop_iterations": 3,
    "stop_hook_count": 1,
    "last_evidence": "investigations/scraping/phase_2/findings.md",
    "uncertainties_remaining": 2,
    "confidence": "medium",
    "test_status": "failing",
    "automation_health": "good"
  }
}
```

### 18. Test-Driven Development Integration
**Decision**: Tests as objective success criteria to constrain optimism

**Core Problem Addressed**: Claude Code has a critical tendency toward overoptimism and fabrication:
- **Claims tasks are complete** when only partially implemented
- **Modifies tests** to match broken implementations instead of fixing code
- **Fabricates evidence** of success (fake test results, non-existent files)
- **Stops prematurely** claiming "good progress" when work is incomplete

**TDD Solution - Locked Tests with Programmatic Verification**:
1. **Write tests first** - `/write_tests` before `/implement` (tests become immutable)
2. **Lock tests** - No test modification allowed after creation
3. **Implementation must pass existing tests** - No shortcuts or test changes
4. **Programmatic verification only** - pytest exit codes, not LLM claims
5. **Evidence via tests** - Test results become primary evidence

**Test Evidence Requirements**:
- All tests must pass for phase completion (verified programmatically)
- Test logs preserved in `investigations/[area]/phase_X/test_results.log`
- Coverage metrics tracked (minimum 80% for critical paths)
- **No test modifications** after initial creation (anti-cheating measure)

**Automated Testing Requirements**:
- Tests auto-run via PostToolUse hooks after implementation
- Test failures auto-inject as uncertainties in CLAUDE.md
- Coverage tracked and validated before phase completion
- Test results become primary evidence for completion claims
- **Hook validates test file integrity** (prevents unauthorized test changes)

### 19. Fresh Instance Evaluator System
**Decision**: Use fresh Claude Code instances as objective judges to prevent cheating

**Core Problem**: Working Claude instance develops psychological pressure to find shortcuts:
- **Scope reduction**: "Task A is hard, let's do simpler Task B instead"
- **Requirement dropping**: "Skip error handling for MVP"
- **Quality compromise**: "Use mock data instead of real API"

**Solution - Independent Evaluation**: Fresh Claude instance evaluates proposed changes objectively

**Evaluator Spawning Methods**:

1. **Subagent Evaluation** (Preferred):
```python
# In autonomous hook
def evaluate_plan_changes(self, original_plan, proposed_changes):
    return {
        "decision": "block",
        "reason": f"""
        Use Task tool to spawn evaluation subagent:
        
        Original requirements: {original_plan}
        Proposed changes: {proposed_changes}
        
        Subagent must determine if changes are:
        1. Legitimate addition (necessary steps discovered)
        2. Scope reduction (removing requirements) 
        3. Quality compromise (lowering standards)
        
        Only proceed if subagent approves changes as legitimate additions.
        """
    }
```

2. **CLI Instance Spawning**:
```python
def spawn_evaluator_claude(self, evaluation_task, context_data):
    eval_dir = self.project_root / ".claude" / "evaluations" / f"eval_{int(time.time())}"
    eval_dir.mkdir(parents=True, exist_ok=True)
    
    # Write evaluation context
    context_file = eval_dir / "evaluation_context.md"
    context_file.write_text(evaluation_prompt)
    
    # Spawn fresh instance
    result = subprocess.run([
        'claude', '--project-dir', str(eval_dir),
        '--prompt', "Read evaluation_context.md and provide evaluation"
    ], capture_output=True, text=True, timeout=300)
    
    return json.loads(result.stdout.split('\n')[-1])
```

**Evaluation Categories**:

**‚úÖ Approved Autonomous Changes**:
- **Missing prerequisites**: "Need OAuth setup before API calls"
- **Technical requirements**: "Need rate limiting to meet API ToS"
- **Discovered blockers**: "API requires different auth method"
- **Additive discoveries**: Adding steps to meet original criteria

**‚ùå Rejected Simplifications**:
- **Scope reduction**: "Use simple API key instead of OAuth"
- **Requirement dropping**: "Skip error handling for now"
- **Quality shortcuts**: "Use mock data instead of real API"
- **Standard lowering**: "Basic version first, full version later"

**Enforcement Mechanism**:
- All plan modifications trigger evaluator subagent
- Working instance cannot override evaluator decisions
- Evaluation results logged in `investigations/evaluations/`
- Anti-cheating patterns detected and blocked automatically

**Directory Structure for Evaluations**:
```
.claude/evaluations/
‚îú‚îÄ‚îÄ eval_[timestamp]/
‚îÇ   ‚îú‚îÄ‚îÄ evaluation_context.md
‚îÇ   ‚îú‚îÄ‚îÄ original_requirements.md
‚îÇ   ‚îú‚îÄ‚îÄ proposed_changes.md
‚îÇ   ‚îî‚îÄ‚îÄ evaluation_result.json
‚îî‚îÄ‚îÄ evaluation_history.log
```

### 20. Claude Code Hook Configuration
**Decision**: Hooks orchestrate autonomous workflow

**Hook Configuration** (`.claude/settings.json`):
```json
{
  "hooks": {
    "SessionStart": [{
      "hooks": [{
        "type": "command",
        "command": "$CLAUDE_PROJECT_DIR/tools/workflow/session_recovery.py",
        "timeout": 15
      }]
    }],
    "Stop": [{
      "hooks": [{
        "type": "command",
        "command": "$CLAUDE_PROJECT_DIR/tools/workflow/workflow_orchestrator.py",
        "timeout": 20
      }]
    }],
    "PostToolUse": [
      {
        "matcher": "Write|Edit|MultiEdit",
        "hooks": [
          {"type": "command", "command": "$CLAUDE_PROJECT_DIR/tools/workflow/evidence_validator.py", "timeout": 30},
          {"type": "command", "command": "$CLAUDE_PROJECT_DIR/tools/workflow/discovery_classifier.py", "timeout": 20},
          {"type": "command", "command": "$CLAUDE_PROJECT_DIR/tools/workflow/state_reconciliation.py", "timeout": 25}
        ]
      }
    ],
    "PreToolUse": [
      {
        "matcher": "Edit|Write|MultiEdit",
        "hooks": [
          {"type": "command", "command": "$CLAUDE_PROJECT_DIR/tools/validate_references.py", "timeout": 15}
        ]
      }
    ]
  }
}
```

**Hook Orchestration Pattern**:
- SessionStart recovers state and resumes workflow from last command
- Stop hook reads state and injects next command via JSON output
- PostToolUse validates evidence, detects discoveries, and reconciles state
- PreToolUse ensures cross-references valid before modifications

**Session Recovery Pattern** (SessionStart):
```python
# Read workflow state from CLAUDE.md
state = parse_claude_md_workflow_state()
if state and state.get("current_command"):
    # Check for dirty lock indicating crash
    if os.path.exists(".claude/.lock/stop.lock"):
        print(f"Recovering from {state['current_command']}")
        # Inject context to resume
        return {
            "hookSpecificOutput": {
                "additionalContext": f"Session recovered. Continue from: {state['current_command']}"
            }
        }
```

**Cross-Reference**: See detailed hook integration points in `hook_mermaid_diagram_full4_w_tdd.txt` with dotted lines showing automation connections.

### 20. Command Injection via Hooks
**Decision**: Hooks control Claude through JSON output

**Stop Hook Control Pattern**:
```python
import os, time, json

# Check for recursion protection first
if input_data.get("stop_hook_active"):
    return {"continue": True, "suppressOutput": True}

# Manual override check
if os.path.exists('.workflow_override'):
    return {"continue": True, "suppressOutput": True}

# Basic lock mechanism to prevent concurrent Stop races
lock_file = ".claude/.lock/stop.lock"
os.makedirs(".claude/.lock", exist_ok=True)
if os.path.exists(lock_file):
    lock_age = time.time() - os.path.getmtime(lock_file)
    if lock_age < 5:  # Lock still fresh
        return {"continue": True, "suppressOutput": True}

# Stop hook loop prevention
state = parse_workflow_state()
if state.get("stop_hook_count", 0) >= 3:
    return {
        "continue": False,
        "stopReason": "Stop hook loop detected. Entering manual mode. Create .workflow_override to continue manually."
    }
    
# Create lock
with open(lock_file, "w") as f:
    f.write(str(time.time()))

# Force Claude to continue with next command
output = {
    "decision": "block",  
    "reason": f"Execute: {next_command}"  # Becomes Claude's next prompt
}
```

**Evidence Validation Pattern** (PreToolUse):
```python
# Use correct field names for PreToolUse
if not references_valid:
    output = {
        "hookSpecificOutput": {
            "hookEventName": "PreToolUse",
            "permissionDecision": "deny",
            "permissionDecisionReason": "Cross-references broken. Fix before editing."
        }
    }
```

**PostToolUse Feedback Pattern**:
```python
# Block on missing evidence in PostToolUse
if evidence_file.is_empty():
    output = {
        "decision": "block",
        "reason": "Evidence validation failed. Rerun tests with verbose output."
    }
```

### 21. Loop Breaking and Recovery
**Decision**: Bounded iteration with escalation strategies

**Loop Breaker Logic**:
- Maximum 7 iterations for any uncertainty resolution loop
- Maximum 3 consecutive Stop hook executions
- Iteration count tracked in workflow state
- Breaker triggers escalation strategy

**Stop Hook Loop Prevention**:
- Track consecutive Stop hook executions in workflow state
- Automatic escalation to manual mode after 3 executions
- `.workflow_override` file as emergency escape mechanism
- Manual intervention request with diagnostic information

**Recovery Strategies**:
1. **Archive and skip**: Move unresolved to `investigations/deferred/` via `/escalate_to_deferred`
2. **Simplify objective**: Reduce scope to achievable subset
3. **Human escalation**: Create detailed report for manual review
4. **Manual override**: Create `.workflow_override` to disable automation

**Cross-Reference**: See loop breaking decision point and escalation flow in `hook_mermaid_diagram_full4_w_tdd.txt`.

### 22. Quality Validation Pipeline
**Decision**: Automated quality checks beyond testing

**Quality Gates**:
- **No hardcoded secrets**: Scan for API keys, passwords
- **Cross-reference integrity**: All references must be valid
- **Evidence completeness**: All claims have supporting evidence
- **Test coverage**: Minimum thresholds for critical paths
- **Stop hook loop prevention**: Monitor automation health
- **State consistency**: Claimed vs actual state verification
- **Automation effectiveness**: Detect when automation makes things worse

**Implementation**:
- PostToolUse hooks run quality validators
- Failures block progression and inject errors
- Quality metrics tracked in workflow state
- Automation health monitoring with escalation triggers

**Enhanced Quality Checks**:
- **Reality checks**: Compare claimed progress with actual file/git/test state
- **Contradiction detection**: Identify inconsistent statements across artifacts
- **Progress validation**: Ensure work actually moves project forward
- **Automation feedback loops**: Detect and break harmful automation patterns

## Tools & Tests Curation Strategy

### 23. Testing vs. CLAUDE.md Reference Strategy
**Key Distinction**: Whether to test something vs. whether to reference it in CLAUDE.md are separate decisions

**Testing Strategy** (What should have tests):
- **Critical Infrastructure**: Tools that break the entire workflow if they fail
- **Complex Logic**: Regex parsing, file system operations, data transformations
- **Integration Points**: API interactions, cross-component workflows
- **Business Logic**: Core domain logic and algorithms
- **Error-Prone Code**: File manipulation, external service calls

**CLAUDE.md Reference Strategy** (Attention economics):
- **High-Value References**: Only tools where recreate cost >> reference cost
- **Critical Dependencies**: Tools that break workflows if missing
- **Cross-Phase Usage**: Tools needed throughout project lifecycle
- **Domain-Specific Logic**: Project-specific insights and algorithms

### 24. Attention Economics & Reference Tradeoffs
**Key Principle**: Every reference in CLAUDE.md reduces Claude's attention to other instructions

**High-value CLAUDE.md references** (worth the attention cost):
- **Recreate Cost >> Reference Cost**: Complex tools that would take significant time/context to rebuild vs. brief reference
- **Frequent Cross-Phase Usage**: Tools needed throughout project lifecycle, not just once
- **Critical Path Dependencies**: Tools that other processes rely on, breaking workflows if recreated incorrectly
- **Domain-Specific Logic**: Project-specific algorithms that embody hard-won insights

**Low-value CLAUDE.md references** (delete rather than reference):
- **Recreate Cost < Reference Cost**: Simple utilities where describing them takes more tokens than rebuilding
- **One-Time Usage**: Tools unlikely to be needed again or in different contexts
- **Generic Patterns**: Standard approaches Claude already knows well
- **Easy Substitution**: Tools with many equivalent alternatives

**Testing vs. CLAUDE.md Decision Matrix**:
| Tool Type | Create Tests? | Reference in CLAUDE.md? | Rationale |
|-----------|---------------|-------------------------|-----------|
| Critical Infrastructure | ‚úÖ Yes | Only if cross-phase | Test for reliability, reference only if frequently used |
| Business Logic | ‚úÖ Yes | ‚úÖ Yes | Both test and reference - core project value |
| Simple Utilities | ‚ùå No | ‚ùå No | Neither needed - easy to recreate |
| Integration Points | ‚úÖ Yes | Depends on complexity | Test for reliability, reference if complex |

## Cross-Reference System & Context Loading

### 25. File Cross-Reference Architecture
**Decision**: Comprehensive traceability chain across all documentation and code

**Traceability Flow**:
```
Behavior Docs ‚Üî Architecture Docs ‚Üî Phase Plans ‚Üî Implementation Files
```

**Cross-Reference Patterns**:
- **Code Files**: Include TRACEABILITY comments linking to phase plans, architecture, behavior docs
- **Phase Plans**: Reference implementation files and related documentation  
- **Architecture Docs**: Link to phase plans and behavior requirements
- **Behavior Docs**: Reference architecture implementations and current phases

**Non-Code Files**: Use companion `.ref` files for JSON, config files, etc.

### 26. Context Loading System
**Decision**: Automatic context loading tool for comprehensive file modification awareness

**Core Tool**: `tools/load_context.py`
- **Input**: Any project file path
- **Output**: Complete context including all cross-references and full text of related files
- **Usage**: MANDATORY before modifying any file

**Context Loading Includes**:
- All behavior docs that reference the target file
- All architecture docs that reference the target file
- All phase plans that reference the target file
- All files with dependencies (imports, imported by)
- Full text content of ALL referenced files
- Planning dependencies vs runtime dependencies

**Dependency Types**:
- **Planning Dependencies**: Development order requirements (Phase 1 ‚Üí Phase 2)
- **Runtime Dependencies**: Import/execution relationships
- **Configuration Dependencies**: Config files used by code files

### 27. Automated Reference Validation
**Decision**: Fail-fast reference validation with automatic error injection

**Validation Tools**:
- **`tools/validate_references.py`**: Check all cross-references are valid file paths
- **Git hooks**: Detect file moves/renames and create update tasks
- **Pre-commit validation**: Block commits with broken references

**Error Integration**:
- **Broken references** ‚Üí Automatic injection into CLAUDE.md error section
- **File moves** ‚Üí Auto-created reference update tasks with specific instructions
- **Missing files** ‚Üí Detailed error logs with search/replace guidance

**Reference Update Workflow**:
1. File moved/renamed detected by git hooks
2. Error automatically injected into CLAUDE.md with update instructions
3. Claude Code sees error and follows provided search/replace guidance
4. Validation tool confirms all references updated
5. Error removed from CLAUDE.md when resolved

### 28. Context Loading Usage Pattern
**Mandatory Workflow for File Modifications**:

```bash
# Step 1: Load complete context before any modification
python tools/load_context.py src/[component]/[file].py > context_[file].txt

# Step 2: Review context file to understand:
# - What behavior requirements this file implements
# - What architecture components it belongs to  
# - What phase plans govern its development
# - What other files depend on it or it depends on
# - Full text of all related documentation

# Step 3: Make modifications with full awareness of impact

# Step 4: Update cross-references if file purpose/location changes

# Step 5: Validate references still work
python tools/validate_references.py
```

### 29. Reference Templates for Reusable Patterns

**Code File Cross-Reference Template**:
```python
"""
[filename].py

TRACEABILITY:
- Phase Plan: /docs/development_roadmap/[phase_file].md (Section X.Y)
- Architecture: /docs/architecture/[arch_file].md ([Component Name])
- Behavior: /docs/behavior/[behavior_file].md ([Requirement Section])

CROSS-REFERENCES:
- Related Files: [list of related files]
- Tests: [list of test files]
- Tools: [list of related tools]
- Config: [list of config files used]

DEPENDENCIES:
- Imports: [list of external imports]
- Imported By: [list of files that import this]
- Planning: Blocks [list], Blocked By [list]
"""
```

**Phase Plan Cross-Reference Template**:
```markdown
## [Section Title]

**Implementation Files:**
- `[file_path]` - [brief description]
- `[file_path]` - [brief description]

**Related Architecture:** [link to architecture doc section]
**Related Behavior:** [link to behavior doc section]
**Dependencies:** [list of planning dependencies]
```

**Non-Code File Reference Template** (`.ref` files):
```markdown
# Cross-References for [filename]

**Traceability:**
- Phase Plan: [path and section]
- Architecture: [path and section]  
- Behavior: [path and section]

**Used By:**
- [list of files that use this config/data]

**Related Files:**
- [list of related configuration or data files]
```

## Integration Points

### 30. Phase Transitions
**Workflow for completing phases**:
1. **Evidence collection** with end-to-end validation
2. **Update phases.md** to mark tasks complete
3. **Archive investigation files** to avoid future confusion
4. **Update CLAUDE.md** for next phase priorities
5. **Error resolution** before phase completion

### 31. Error Resolution Integration
**When errors block progress**:
1. **Automatic injection** into CLAUDE.md error section
2. **Investigation documentation** in investigations/errors/
3. **Pattern analysis** for recurring issues
4. **Resolution testing** with evidence collection
5. **Knowledge transfer** to prevent future occurrences

## Current Implementation Status

### 32. Built and Tested Infrastructure
**‚úÖ Complete and Operational**:
- Cross-reference validation system with git integration
- Context loading for comprehensive file modification awareness
- Error injection and management with automatic CLAUDE.md updates
- Archive system with provenance tracking
- Comprehensive test suite
- File organization guidelines for Claude Code

**‚úÖ Git Workflow Integration**:
- Pre-commit hooks preventing broken reference commits
- Post-commit hooks detecting file moves and creating update tasks
- Automatic error injection into CLAUDE.md for immediate visibility

**‚úÖ Documentation Framework**:
- Complete architectural decision documentation
- Reusable templates for cross-references
- Clear guidelines for file placement and organization
- Evidence-based development requirements

**üöß In Development - Autonomous Workflow System**:
- Workflow orchestrator with Stop hook command injection
- Evidence validator with PostToolUse integration
- State reconciliation for automation health monitoring
- Loop prevention and manual override mechanisms

## Future Considerations

### 33. Scaling Decisions
**As project grows**:
- **Modular logging** strategy can expand to new components
- **Investigation structure** can add new research areas
- **Phase management** can accommodate additional development streams
- **Error tracking** can scale to multiple parallel development efforts

### 34. Team Collaboration
**Multi-developer readiness**:
- **Shared CLAUDE.md** through git with automatic updates
- **Investigation documentation** provides context for team members
- **Error visibility** prevents duplicate debugging efforts
- **Evidence-based development** enables verification of team member work

---

*This document captures architectural decisions as they're made. Update when new structural decisions are finalized.*